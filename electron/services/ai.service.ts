import { ConfigService } from './config.service'
import { HttpsProxyAgent } from 'https-proxy-agent'
import { SocksProxyAgent } from 'socks-proxy-agent'
import * as https from 'https'
import * as http from 'http'

export interface AiMessage {
  role: 'system' | 'user' | 'assistant' | 'tool'
  content: string
  tool_call_id?: string  // ç”¨äº tool è§’è‰²çš„æ¶ˆæ¯
  tool_calls?: ToolCall[]  // ç”¨äº assistant è§’è‰²çš„å·¥å…·è°ƒç”¨
  reasoning_content?: string  // ç”¨äº think æ¨¡å‹çš„æ€è€ƒå†…å®¹ï¼ˆDeepSeek-R1 ç­‰ï¼‰
}

// Tool Calling ç›¸å…³ç±»å‹
export interface ToolDefinition {
  type: 'function'
  function: {
    name: string
    description: string
    parameters: {
      type: 'object'
      properties: Record<string, {
        type: string
        description: string
        enum?: string[]
      }>
      required?: string[]
    }
  }
}

export interface ToolCall {
  id: string
  type: 'function'
  function: {
    name: string
    arguments: string  // JSON å­—ç¬¦ä¸²
  }
}

export interface ChatWithToolsResult {
  content?: string
  tool_calls?: ToolCall[]
  finish_reason?: 'stop' | 'tool_calls' | 'length'
  reasoning_content?: string  // think æ¨¡å‹çš„æ€è€ƒå†…å®¹
}

export interface AiProfile {
  id: string
  name: string
  apiUrl: string
  apiKey: string
  model: string
  proxy?: string
  contextLength?: number  // æ¨¡å‹ä¸Šä¸‹æ–‡é•¿åº¦ï¼ˆtokensï¼‰ï¼Œé»˜è®¤ 8000
}

export class AiService {
  private configService: ConfigService
  // ä½¿ç”¨ Map å­˜å‚¨å¤šä¸ªè¯·æ±‚çš„ AbortControllerï¼Œæ”¯æŒå¤šä¸ªç»ˆç«¯åŒæ—¶è¯·æ±‚
  private abortControllers: Map<string, AbortController> = new Map()

  constructor() {
    this.configService = new ConfigService()
  }

  /**
   * ä¸­æ­¢æŒ‡å®šè¯·æ±‚ï¼Œå¦‚æœä¸ä¼  requestId åˆ™ä¸­æ­¢æ‰€æœ‰è¯·æ±‚
   */
  abort(requestId?: string): void {
    if (requestId) {
      const controller = this.abortControllers.get(requestId)
      if (controller) {
        controller.abort()
        this.abortControllers.delete(requestId)
      }
    } else {
      // ä¸­æ­¢æ‰€æœ‰è¯·æ±‚
      this.abortControllers.forEach(controller => controller.abort())
      this.abortControllers.clear()
    }
  }

  /**
   * è·å–ä»£ç† Agent
   */
  private getProxyAgent(proxyUrl: string): HttpsProxyAgent<string> | SocksProxyAgent | undefined {
    if (!proxyUrl) return undefined

    if (proxyUrl.startsWith('socks')) {
      return new SocksProxyAgent(proxyUrl)
    } else {
      return new HttpsProxyAgent(proxyUrl)
    }
  }

  /**
   * è·å–å½“å‰ AI Profile
   */
  private async getCurrentProfile(profileId?: string): Promise<AiProfile | null> {
    const profiles = this.configService.getAiProfiles()
    if (profiles.length === 0) return null

    if (profileId) {
      return profiles.find(p => p.id === profileId) || null
    }

    const activeId = this.configService.getActiveAiProfile()
    if (activeId) {
      return profiles.find(p => p.id === activeId) || profiles[0]
    }

    return profiles[0]
  }

  /**
   * å‘é€èŠå¤©è¯·æ±‚ï¼ˆéæµå¼ï¼‰
   */
  async chat(messages: AiMessage[], profileId?: string): Promise<string> {
    const profile = await this.getCurrentProfile(profileId)
    if (!profile) {
      throw new Error('æœªé…ç½® AI æ¨¡å‹ï¼Œè¯·å…ˆåœ¨è®¾ç½®ä¸­æ·»åŠ  AI é…ç½®')
    }

    const requestBody = {
      model: profile.model,
      messages,
      temperature: 0.7,
      max_tokens: 2048
    }

    try {
      const data = await this.makeRequest<{
        choices?: { message?: { content?: string } }[]
        error?: { message?: string; code?: string; type?: string }
      }>(profile, requestBody)

      if (data.error) {
        // æ£€æµ‹ä¸Šä¸‹æ–‡è¶…é™é”™è¯¯
        const errorMsg = data.error.message?.toLowerCase() || ''
        const errorCode = data.error.code?.toLowerCase() || ''
        
        if (errorMsg.includes('context_length') || 
            errorMsg.includes('maximum context') ||
            (errorMsg.includes('token') && errorMsg.includes('limit')) ||
            errorCode.includes('context_length')) {
          throw new Error(`ä¸Šä¸‹æ–‡è¶…å‡ºæ¨¡å‹é™åˆ¶ã€‚è¯·æ¸…é™¤éƒ¨åˆ†å¯¹è¯å†å²åé‡è¯•ã€‚`)
        }
        
        throw new Error(`AI API é”™è¯¯: ${data.error.message}`)
      }

      return data.choices?.[0]?.message?.content || ''
    } catch (error) {
      if (error instanceof Error) {
        if (error.message.includes('ä¸Šä¸‹æ–‡è¶…å‡º')) {
          throw error
        }
        const msg = error.message.toLowerCase()
        if (msg.includes('context_length') || 
            msg.includes('maximum context') ||
            (msg.includes('token') && msg.includes('limit'))) {
          throw new Error(`ä¸Šä¸‹æ–‡è¶…å‡ºæ¨¡å‹é™åˆ¶ã€‚è¯·æ¸…é™¤éƒ¨åˆ†å¯¹è¯å†å²åé‡è¯•ã€‚`)
        }
        throw new Error(`AI è¯·æ±‚å¤±è´¥: ${error.message}`)
      }
      throw error
    }
  }

  /**
   * å‘é€ HTTP è¯·æ±‚ï¼ˆæ”¯æŒä»£ç†ï¼‰
   */
  private makeRequest<T>(profile: AiProfile, body: object, signal?: AbortSignal): Promise<T> {
    return new Promise((resolve, reject) => {
      const url = new URL(profile.apiUrl)
      const isHttps = url.protocol === 'https:'
      const httpModule = isHttps ? https : http

      const options: https.RequestOptions = {
        hostname: url.hostname,
        port: url.port || (isHttps ? 443 : 80),
        path: url.pathname + url.search,
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${profile.apiKey}`
        }
      }

      // åº”ç”¨ä»£ç†
      if (profile.proxy) {
        options.agent = this.getProxyAgent(profile.proxy)
      }

      const req = httpModule.request(options, (res) => {
        let data = ''
        res.on('data', (chunk) => {
          data += chunk
        })
        res.on('end', () => {
          if (res.statusCode && res.statusCode >= 200 && res.statusCode < 300) {
            try {
              resolve(JSON.parse(data))
            } catch {
              reject(new Error(`å“åº”è§£æå¤±è´¥: ${data}`))
            }
          } else {
            reject(new Error(`AI API è¯·æ±‚å¤±è´¥: ${res.statusCode} - ${data}`))
          }
        })
      })

      req.on('error', (err) => {
        reject(new Error(`è¯·æ±‚é”™è¯¯: ${err.message}`))
      })

      // æ”¯æŒä¸­æ­¢è¯·æ±‚
      if (signal) {
        signal.addEventListener('abort', () => {
          req.destroy()
          reject(new Error('è¯·æ±‚å·²ä¸­æ­¢'))
        })
      }

      req.write(JSON.stringify(body))
      req.end()
    })
  }

  /**
   * å‘é€èŠå¤©è¯·æ±‚ï¼ˆæµå¼ï¼Œæ”¯æŒä»£ç†ï¼‰
   * æ”¯æŒ think æ¨¡å‹ï¼ˆå¦‚ DeepSeek-R1ï¼‰çš„ reasoning_content å­—æ®µ
   * @param requestId è¯·æ±‚ IDï¼Œç”¨äºæ”¯æŒå¤šä¸ªç»ˆç«¯åŒæ—¶è¯·æ±‚
   */
  async chatStream(
    messages: AiMessage[],
    onChunk: (chunk: string) => void,
    onDone: () => void,
    onError: (error: string) => void,
    profileId?: string,
    requestId?: string
  ): Promise<void> {
    const profile = await this.getCurrentProfile(profileId)
    if (!profile) {
      onError('æœªé…ç½® AI æ¨¡å‹ï¼Œè¯·å…ˆåœ¨è®¾ç½®ä¸­æ·»åŠ  AI é…ç½®')
      return
    }

    const requestBody = {
      model: profile.model,
      messages,
      temperature: 0.7,
      max_tokens: 2048,
      stream: true
    }

    // åˆ›å»º AbortControllerï¼Œä½¿ç”¨ requestId æˆ–ç”Ÿæˆä¸€ä¸ªå”¯ä¸€ ID
    const reqId = requestId || `req_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`
    const abortController = new AbortController()
    this.abortControllers.set(reqId, abortController)

    try {
      const url = new URL(profile.apiUrl)
      const isHttps = url.protocol === 'https:'
      const httpModule = isHttps ? https : http

      const options: https.RequestOptions = {
        hostname: url.hostname,
        port: url.port || (isHttps ? 443 : 80),
        path: url.pathname + url.search,
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${profile.apiKey}`
        }
      }

      // åº”ç”¨ä»£ç†
      if (profile.proxy) {
        options.agent = this.getProxyAgent(profile.proxy)
      }

      let hasReasoningOutput = false  // æ ‡è®°æ˜¯å¦å·²è¾“å‡ºæ€è€ƒå†…å®¹
      let hasContentOutput = false    // æ ‡è®°æ˜¯å¦å·²è¾“å‡ºæ­£å¸¸å†…å®¹

      const req = httpModule.request(options, (res) => {
        if (res.statusCode && (res.statusCode < 200 || res.statusCode >= 300)) {
          let errorData = ''
          res.on('data', (chunk) => { errorData += chunk })
          res.on('end', () => {
            // æ£€æµ‹ä¸Šä¸‹æ–‡è¶…é™é”™è¯¯
            const errorLower = errorData.toLowerCase()
            if (errorLower.includes('context_length') || 
                errorLower.includes('maximum context') ||
                (errorLower.includes('token') && errorLower.includes('limit')) ||
                errorLower.includes('too many tokens')) {
              onError(`ä¸Šä¸‹æ–‡è¶…å‡ºæ¨¡å‹é™åˆ¶ã€‚è¯·æ¸…é™¤éƒ¨åˆ†å¯¹è¯å†å²åé‡è¯•ã€‚`)
            } else {
              onError(`AI API è¯·æ±‚å¤±è´¥: ${res.statusCode} - ${errorData}`)
            }
          })
          return
        }

        let buffer = ''

        res.on('data', (chunk: Buffer) => {
          buffer += chunk.toString()
          const lines = buffer.split('\n')
          // ä¿ç•™æœ€åä¸€ä¸ªå¯èƒ½ä¸å®Œæ•´çš„è¡Œ
          buffer = lines.pop() || ''

          for (const line of lines) {
            const trimmedLine = line.trim()
            if (!trimmedLine) continue

            if (trimmedLine.startsWith('data: ')) {
              const data = trimmedLine.slice(6)
              if (data === '[DONE]') {
                // å¦‚æœåªæœ‰æ€è€ƒå†…å®¹æ²¡æœ‰å›å¤ï¼Œæ·»åŠ ç»“æŸæ ‡è®°
                if (hasReasoningOutput && !hasContentOutput) {
                  onChunk('\n\n</details>\n')
                }
                onDone()
                return
              }

              try {
                const parsed = JSON.parse(data) as {
                  choices?: { delta?: { content?: string; reasoning_content?: string } }[]
                }
                const delta = parsed.choices?.[0]?.delta
                
                // å¤„ç† think æ¨¡å‹çš„ reasoning_contentï¼ˆæ€è€ƒè¿‡ç¨‹ï¼‰
                if (delta?.reasoning_content) {
                  if (!hasReasoningOutput) {
                    hasReasoningOutput = true
                    // ä½¿ç”¨ details æ ‡ç­¾åˆ›å»ºå¯æŠ˜å çš„æ€è€ƒåŒºåŸŸ
                    onChunk('<details open>\n<summary>ğŸ¤” <strong>æ€è€ƒè¿‡ç¨‹</strong>ï¼ˆç‚¹å‡»æŠ˜å ï¼‰</summary>\n\n<blockquote>\n\n')
                  }
                  onChunk(delta.reasoning_content)
                }
                
                // å¤„ç†æ­£å¸¸çš„ content
                if (delta?.content) {
                  // å¦‚æœä¹‹å‰æœ‰æ€è€ƒè¿‡ç¨‹ï¼Œç°åœ¨å¼€å§‹è¾“å‡ºæœ€ç»ˆå†…å®¹ï¼Œæ·»åŠ åˆ†éš”
                  if (hasReasoningOutput && !hasContentOutput) {
                    hasContentOutput = true
                    onChunk('\n\n</blockquote>\n</details>\n\n---\n\n### ğŸ’¬ å›å¤\n\n')
                  }
                  onChunk(delta.content)
                }
              } catch {
                // å¿½ç•¥è§£æé”™è¯¯
              }
            }
          }
        })

        res.on('end', () => {
          onDone()
        })

        res.on('error', (err) => {
          onError(`å“åº”é”™è¯¯: ${err.message}`)
        })
      })

      req.on('error', (err) => {
        if (err.message === 'è¯·æ±‚å·²ä¸­æ­¢') {
          onDone()
          return
        }
        onError(`è¯·æ±‚é”™è¯¯: ${err.message}`)
      })

      // æ”¯æŒä¸­æ­¢è¯·æ±‚
      abortController.signal.addEventListener('abort', () => {
        req.destroy()
      })

      req.write(JSON.stringify(requestBody))
      req.end()
    } catch (error) {
      if (error instanceof Error) {
        onError(`AI è¯·æ±‚å¤±è´¥: ${error.message}`)
      } else {
        onError('AI è¯·æ±‚å¤±è´¥: æœªçŸ¥é”™è¯¯')
      }
    }
  }

  /**
   * å‘é€å¸¦å·¥å…·è°ƒç”¨çš„èŠå¤©è¯·æ±‚ï¼ˆéæµå¼ï¼‰
   * ç”¨äº Agent æ¨¡å¼ï¼Œæ”¯æŒ function calling
   */
  async chatWithTools(
    messages: AiMessage[],
    tools: ToolDefinition[],
    profileId?: string
  ): Promise<ChatWithToolsResult> {
    const profile = await this.getCurrentProfile(profileId)
    if (!profile) {
      throw new Error('æœªé…ç½® AI æ¨¡å‹ï¼Œè¯·å…ˆåœ¨è®¾ç½®ä¸­æ·»åŠ  AI é…ç½®')
    }

    // è½¬æ¢æ¶ˆæ¯æ ¼å¼ï¼Œå¤„ç† tool_calls å’Œ reasoning_contentï¼ˆæ”¯æŒ think æ¨¡å‹ï¼‰
    const formattedMessages = messages.map(msg => {
      if (msg.role === 'tool') {
        return {
          role: 'tool' as const,
          content: msg.content,
          tool_call_id: msg.tool_call_id
        }
      }
      if (msg.role === 'assistant' && msg.tool_calls) {
        const assistantMsg: {
          role: 'assistant'
          content: string | null
          tool_calls: ToolCall[]
          reasoning_content?: string
        } = {
          role: 'assistant' as const,
          content: msg.content || null,
          tool_calls: msg.tool_calls
        }
        if (msg.reasoning_content) {
          assistantMsg.reasoning_content = msg.reasoning_content
        }
        return assistantMsg
      }
      return {
        role: msg.role,
        content: msg.content
      }
    })

    const requestBody = {
      model: profile.model,
      messages: formattedMessages,
      tools: tools.length > 0 ? tools : undefined,
      tool_choice: tools.length > 0 ? 'auto' : undefined,
      temperature: 0.7,
      max_tokens: 4096
    }

    try {
      const data = await this.makeRequest<{
        choices?: {
          message?: {
            content?: string | null
            tool_calls?: ToolCall[]
          }
          finish_reason?: string
        }[]
        error?: { message?: string; code?: string; type?: string }
      }>(profile, requestBody)

      if (data.error) {
        // æ£€æµ‹ä¸Šä¸‹æ–‡è¶…é™é”™è¯¯
        const errorMsg = data.error.message?.toLowerCase() || ''
        const errorCode = data.error.code?.toLowerCase() || ''
        const errorType = data.error.type?.toLowerCase() || ''
        
        if (errorMsg.includes('context_length') || 
            errorMsg.includes('maximum context') ||
            errorMsg.includes('token') && errorMsg.includes('limit') ||
            errorMsg.includes('too many tokens') ||
            errorMsg.includes('too long') ||
            errorCode.includes('context_length') ||
            errorType.includes('context_length')) {
          throw new Error(`ä¸Šä¸‹æ–‡è¶…å‡ºæ¨¡å‹é™åˆ¶ã€‚è¯·æ¸…é™¤éƒ¨åˆ†å¯¹è¯å†å²åé‡è¯•ã€‚\nåŸå§‹é”™è¯¯: ${data.error.message}`)
        }
        
        throw new Error(`AI API é”™è¯¯: ${data.error.message}`)
      }

      const choice = data.choices?.[0]
      if (!choice) {
        throw new Error('AI è¿”å›ç»“æœä¸ºç©º')
      }

      return {
        content: choice.message?.content || undefined,
        tool_calls: choice.message?.tool_calls,
        finish_reason: choice.finish_reason as ChatWithToolsResult['finish_reason']
      }
    } catch (error) {
      if (error instanceof Error) {
        // å¦‚æœå·²ç»æ˜¯æ ¼å¼åŒ–çš„é”™è¯¯ï¼Œç›´æ¥æŠ›å‡º
        if (error.message.includes('ä¸Šä¸‹æ–‡è¶…å‡º')) {
          throw error
        }
        // å†æ¬¡æ£€æµ‹é”™è¯¯æ¶ˆæ¯ä¸­çš„ä¸Šä¸‹æ–‡è¶…é™
        const msg = error.message.toLowerCase()
        if (msg.includes('context_length') || 
            msg.includes('maximum context') ||
            (msg.includes('token') && msg.includes('limit'))) {
          throw new Error(`ä¸Šä¸‹æ–‡è¶…å‡ºæ¨¡å‹é™åˆ¶ã€‚è¯·æ¸…é™¤éƒ¨åˆ†å¯¹è¯å†å²åé‡è¯•ã€‚`)
        }
        throw new Error(`AI è¯·æ±‚å¤±è´¥: ${error.message}`)
      }
      throw error
    }
  }

  /**
   * å¸¦å·¥å…·çš„èŠå¤©ï¼ˆæµå¼ï¼‰
   * ç”¨äº Agent æ¨¡å¼ï¼Œæ”¯æŒ function calling å’Œæµå¼è¾“å‡º
   * æ”¯æŒ think æ¨¡å‹ï¼ˆå¦‚ DeepSeek-R1ï¼‰çš„ reasoning_content å­—æ®µ
   */
  async chatWithToolsStream(
    messages: AiMessage[],
    tools: ToolDefinition[],
    onChunk: (chunk: string) => void,
    onToolCall: (toolCalls: ToolCall[]) => void,
    onDone: (result: ChatWithToolsResult) => void,
    onError: (error: string) => void,
    profileId?: string,
    onToolCallProgress?: (toolName: string, argsLength: number) => void  // å·¥å…·è°ƒç”¨å‚æ•°ç”Ÿæˆè¿›åº¦
  ): Promise<void> {
    const profile = await this.getCurrentProfile(profileId)
    if (!profile) {
      onError('æœªé…ç½® AI æ¨¡å‹ï¼Œè¯·å…ˆåœ¨è®¾ç½®ä¸­æ·»åŠ  AI é…ç½®')
      return
    }

    // è½¬æ¢æ¶ˆæ¯æ ¼å¼ï¼Œæ”¯æŒ think æ¨¡å‹çš„ reasoning_content
    const formattedMessages = messages.map(msg => {
      if (msg.role === 'tool') {
        return {
          role: 'tool' as const,
          content: msg.content,
          tool_call_id: msg.tool_call_id
        }
      }
      if (msg.role === 'assistant' && msg.tool_calls) {
        // DeepSeek think æ¨¡å‹è¦æ±‚åŒ…å« reasoning_content
        const assistantMsg: {
          role: 'assistant'
          content: string | null
          tool_calls: ToolCall[]
          reasoning_content?: string
        } = {
          role: 'assistant' as const,
          content: msg.content || null,
          tool_calls: msg.tool_calls
        }
        if (msg.reasoning_content) {
          assistantMsg.reasoning_content = msg.reasoning_content
        }
        return assistantMsg
      }
      return {
        role: msg.role,
        content: msg.content
      }
    })

    const requestBody = {
      model: profile.model,
      messages: formattedMessages,
      tools: tools.length > 0 ? tools : undefined,
      tool_choice: tools.length > 0 ? 'auto' : undefined,
      temperature: 0.7,
      max_tokens: 4096,
      stream: true
    }

    try {
      const url = new URL(profile.apiUrl)
      const isHttps = url.protocol === 'https:'
      const httpModule = isHttps ? https : http

      const options: https.RequestOptions = {
        hostname: url.hostname,
        port: url.port || (isHttps ? 443 : 80),
        path: url.pathname + url.search,
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${profile.apiKey}`
        }
      }

      if (profile.proxy) {
        options.agent = this.getProxyAgent(profile.proxy)
      }

      let content = ''
      let reasoningContent = ''  // ç”¨äºæ”¶é›† think æ¨¡å‹çš„æ€è€ƒå†…å®¹
      let toolCalls: ToolCall[] = []
      let finishReason: string | undefined
      let hasReasoningOutput = false  // æ ‡è®°æ˜¯å¦å·²è¾“å‡ºæ€è€ƒå†…å®¹çš„å¼€å§‹æ ‡è®°
      let hasContentOutput = false    // æ ‡è®°æ˜¯å¦å·²å¼€å§‹è¾“å‡ºæ­£å¸¸å†…å®¹

      const req = httpModule.request(options, (res) => {
        // å¤„ç† HTTP é”™è¯¯
        if (res.statusCode && (res.statusCode < 200 || res.statusCode >= 300)) {
          let errorData = ''
          res.on('data', (chunk) => { errorData += chunk })
          res.on('end', () => {
            onError(`AI API è¯·æ±‚å¤±è´¥: ${res.statusCode} - ${errorData}`)
          })
          return
        }

        let buffer = ''

        res.on('data', (chunk: Buffer) => {
          buffer += chunk.toString()
          const lines = buffer.split('\n')
          buffer = lines.pop() || ''

          for (const line of lines) {
            if (line.startsWith('data: ')) {
              const data = line.slice(6).trim()
              if (data === '[DONE]') {
                // å¦‚æœæœ‰æ€è€ƒå†…å®¹ä½†æ²¡æœ‰æœ€ç»ˆå†…å®¹
                const finalContent = content || (reasoningContent ? `ğŸ¤” **æ€è€ƒè¿‡ç¨‹**\n\n> ${reasoningContent.replace(/\n/g, '\n> ')}` : undefined)
                onDone({
                  content: finalContent,
                  tool_calls: toolCalls.length > 0 ? toolCalls : undefined,
                  finish_reason: finishReason as ChatWithToolsResult['finish_reason'],
                  reasoning_content: reasoningContent || undefined  // è¿”å›åŸå§‹æ€è€ƒå†…å®¹ï¼Œç”¨äºæ¶ˆæ¯å†å²
                })
                return
              }

              try {
                const json = JSON.parse(data)
                const delta = json.choices?.[0]?.delta
                const reason = json.choices?.[0]?.finish_reason

                if (reason) {
                  finishReason = reason
                }

                // å¤„ç† think æ¨¡å‹çš„ reasoning_contentï¼ˆæ€è€ƒè¿‡ç¨‹ï¼‰
                // DeepSeek-R1 ç­‰æ¨¡å‹ä¼šè¿”å› reasoning_content å­—æ®µ
                if (delta?.reasoning_content) {
                  // ç¬¬ä¸€æ¬¡æ”¶åˆ° reasoning_content æ—¶ï¼Œè¾“å‡ºå¼€å§‹æ ‡è®°
                  if (!hasReasoningOutput) {
                    hasReasoningOutput = true
                    // Agent æ¨¡å¼ï¼šç®€å•çš„æ€è€ƒæŒ‡ç¤ºï¼Œä¸ä½¿ç”¨ HTML
                    onChunk('ğŸ¤” **æ€è€ƒä¸­...**\n\n> ')
                  }
                  reasoningContent += delta.reasoning_content
                  // è¾“å‡ºæ€è€ƒå†…å®¹ï¼Œä½¿ç”¨å¼•ç”¨æ ¼å¼
                  onChunk(delta.reasoning_content.replace(/\n/g, '\n> '))
                }

                // å¤„ç†æ­£å¸¸çš„ contentï¼ˆæœ€ç»ˆå›å¤ï¼‰
                if (delta?.content) {
                  // å¦‚æœä¹‹å‰æœ‰æ€è€ƒè¿‡ç¨‹ï¼Œç°åœ¨å¼€å§‹è¾“å‡ºæœ€ç»ˆå†…å®¹ï¼Œæ·»åŠ åˆ†éš”
                  if (hasReasoningOutput && !hasContentOutput) {
                    hasContentOutput = true
                    onChunk('\n\n---\n\n**å›å¤ï¼š** ')
                  }
                  content += delta.content
                  onChunk(delta.content)
                }

                // å¤„ç† tool_calls æµå¼æ›´æ–°
                if (delta?.tool_calls) {
                  // å¦‚æœæœ‰æ€è€ƒè¿‡ç¨‹è¿˜æ²¡å…³é—­ï¼Œå…ˆå…³é—­
                  if (hasReasoningOutput && !hasContentOutput) {
                    hasContentOutput = true
                    onChunk('\n\n')
                  }
                  
                  for (const tc of delta.tool_calls) {
                    const index = tc.index ?? 0
                    if (!toolCalls[index]) {
                      toolCalls[index] = {
                        id: tc.id || '',
                        type: 'function',
                        function: {
                          name: tc.function?.name || '',
                          arguments: tc.function?.arguments || ''
                        }
                      }
                    } else {
                      if (tc.id) {
                        toolCalls[index].id = tc.id
                      }
                      if (tc.function?.name) {
                        toolCalls[index].function.name = tc.function.name
                      }
                      if (tc.function?.arguments) {
                        toolCalls[index].function.arguments += tc.function.arguments
                      }
                    }
                    // é€šçŸ¥å·¥å…·è°ƒç”¨å‚æ•°ç”Ÿæˆè¿›åº¦
                    if (onToolCallProgress && toolCalls[index]) {
                      const toolName = toolCalls[index].function.name
                      const argsLength = toolCalls[index].function.arguments.length
                      onToolCallProgress(toolName, argsLength)
                    }
                  }
                }
              } catch {
                // å¿½ç•¥è§£æé”™è¯¯
              }
            }
          }
        })

        res.on('end', () => {
          // å¦‚æœæœ‰å·¥å…·è°ƒç”¨ï¼Œé€šçŸ¥ä¸€æ¬¡
          if (toolCalls.length > 0) {
            onToolCall(toolCalls)
          }
          // å¦‚æœæœ‰æ€è€ƒå†…å®¹ä½†æ²¡æœ‰æœ€ç»ˆå†…å®¹ï¼ŒæŠŠæ€è€ƒå†…å®¹ä½œä¸ºæœ€ç»ˆå†…å®¹
          const finalContent = content || (reasoningContent ? `ğŸ¤” **æ€è€ƒè¿‡ç¨‹**\n\n> ${reasoningContent.replace(/\n/g, '\n> ')}` : undefined)
          onDone({
            content: finalContent,
            tool_calls: toolCalls.length > 0 ? toolCalls : undefined,
            finish_reason: finishReason as ChatWithToolsResult['finish_reason'],
            reasoning_content: reasoningContent || undefined  // è¿”å›åŸå§‹æ€è€ƒå†…å®¹ï¼Œç”¨äºæ¶ˆæ¯å†å²
          })
        })

        res.on('error', (err) => {
          onError(`è¯·æ±‚é”™è¯¯: ${err.message}`)
        })
      })

      req.on('error', (err) => {
        onError(`è¯·æ±‚å¤±è´¥: ${err.message}`)
      })

      req.write(JSON.stringify(requestBody))
      req.end()
    } catch (error) {
      if (error instanceof Error) {
        onError(`AI è¯·æ±‚å¤±è´¥: ${error.message}`)
      } else {
        onError('AI è¯·æ±‚å¤±è´¥')
      }
    }
  }

  /**
   * ç”Ÿæˆå‘½ä»¤è§£é‡Šçš„ prompt
   */
  static getExplainCommandPrompt(command: string): AiMessage[] {
    return [
      {
        role: 'system',
        content:
          'ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ Linux/Unix ç³»ç»Ÿç®¡ç†å‘˜åŠ©æ‰‹ã€‚ç”¨æˆ·ä¼šç»™ä½ ä¸€ä¸ªå‘½ä»¤ï¼Œè¯·ç”¨ä¸­æ–‡ç®€æ´åœ°è§£é‡Šè¿™ä¸ªå‘½ä»¤çš„ä½œç”¨ã€å‚æ•°å«ä¹‰ï¼Œä»¥åŠå¯èƒ½çš„æ³¨æ„äº‹é¡¹ã€‚'
      },
      {
        role: 'user',
        content: `è¯·è§£é‡Šè¿™ä¸ªå‘½ä»¤ï¼š\n\`\`\`\n${command}\n\`\`\``
      }
    ]
  }

  /**
   * ç”Ÿæˆé”™è¯¯è¯Šæ–­çš„ prompt
   */
  static getDiagnoseErrorPrompt(error: string, context?: string): AiMessage[] {
    return [
      {
        role: 'system',
        content:
          'ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è¿ç»´å·¥ç¨‹å¸ˆåŠ©æ‰‹ã€‚ç”¨æˆ·ä¼šç»™ä½ ä¸€ä¸ªé”™è¯¯ä¿¡æ¯ï¼Œè¯·ç”¨ä¸­æ–‡åˆ†æé”™è¯¯åŸå› ï¼Œå¹¶æä¾›å¯èƒ½çš„è§£å†³æ–¹æ¡ˆã€‚'
      },
      {
        role: 'user',
        content: `è¯·åˆ†æè¿™ä¸ªé”™è¯¯å¹¶æä¾›è§£å†³æ–¹æ¡ˆï¼š\n\`\`\`\n${error}\n\`\`\`${context ? `\n\nä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š\n${context}` : ''}`
      }
    ]
  }

  /**
   * ç”Ÿæˆè‡ªç„¶è¯­è¨€è½¬å‘½ä»¤çš„ prompt
   */
  static getNaturalToCommandPrompt(description: string, os?: string): AiMessage[] {
    return [
      {
        role: 'system',
        content: `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å‘½ä»¤è¡ŒåŠ©æ‰‹ã€‚ç”¨æˆ·ä¼šç”¨è‡ªç„¶è¯­è¨€æè¿°ä»–æƒ³åšçš„äº‹æƒ…ï¼Œè¯·ç”Ÿæˆå¯¹åº”çš„å‘½ä»¤ã€‚${os ? `å½“å‰æ“ä½œç³»ç»Ÿæ˜¯ ${os}ã€‚` : ''}è¯·åªè¿”å›å‘½ä»¤æœ¬èº«ï¼Œå¦‚æœæœ‰å¤šä¸ªå‘½ä»¤è¯·ç”¨æ¢è¡Œåˆ†éš”ï¼Œä¸éœ€è¦é¢å¤–è§£é‡Šã€‚`
      },
      {
        role: 'user',
        content: description
      }
    ]
  }
}

